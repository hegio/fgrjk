name: Sync & Enhance Proxy Nodes

on:
  schedule:
    - cron: '0 */3 * * *'  # æ¯3å°æ—¶åŒæ­¥
  workflow_dispatch:

jobs:
  sync-and-enhance:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: pip install pyyaml

    - name: Download new nodes file (v2fgrjk)
      run: |
        echo "Downloading v2fgrjk from upstream..."
        
        # å°è¯• ghfast.top ä»£ç†
        if curl -L --fail --max-time 30 -o "v2fgrjk.tmp" "https://ghfast.top/https://raw.githubusercontent.com/FGBLH/fgrjk/main/v2fgrjk"; then
          echo "âœ“ Downloaded via ghfast.top"
        # å¤±è´¥åˆ™å°è¯•ç›´è¿
        elif curl -L --fail --max-time 30 -o "v2fgrjk.tmp" "https://raw.githubusercontent.com/FGBLH/fgrjk/main/v2fgrjk"; then
          echo "âœ“ Downloaded via direct"
        else
          echo "::error::Failed to download v2fgrjk"
          exit 1
        fi
        
        # æ£€æŸ¥æ–‡ä»¶æœ‰æ•ˆæ€§
        if [ -s "v2fgrjk.tmp" ]; then
          mv "v2fgrjk.tmp" "v2fgrjk"
          echo "âœ“ Saved v2fgrjk ($(wc -l < v2fgrjk) lines)"
        else
          echo "::error::Downloaded file is empty"
          rm -f "v2fgrjk.tmp"
          exit 1
        fi

    - name: Decode v2fgrjk to plain text
      run: |
        cat > decode.py << 'EOF'
        import base64

        # è¯»å–æ–°æ–‡ä»¶ v2fgrjk
        with open('v2fgrjk', 'r', encoding='utf-8') as f:
            content = f.read()

        # å°è¯• Base64 è§£ç ï¼ˆæœºåœºè®¢é˜…é€šå¸¸ Base64 ç¼–ç ï¼‰
        try:
            # è¡¥å…¨ padding
            padding = 4 - len(content) % 4
            if padding != 4:
                content += '=' * padding
            
            decoded = base64.b64decode(content).decode('utf-8')
            lines = [l.strip() for l in decoded.split('\n') if l.strip()]
            print(f"âœ“ Decoded Base64: {len(lines)} nodes")
        except Exception as e:
            # å¦‚æœä¸æ˜¯ Base64ï¼ŒæŒ‰æ˜æ–‡å¤„ç†
            lines = [l.strip() for l in content.split('\n') if l.strip()]
            print(f"âœ“ Plain text mode: {len(lines)} lines")

        # ä¿å­˜æ˜æ–‡ä¾›åç»­å¤„ç†
        with open('nodes_plain.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        print("Generated nodes_plain.txt")
        EOF
        
        python3 decode.py

    - name: Generate Clash config (from v2fgrjk)
      run: |
        cat > generate_clash.py << 'EOF'
        import yaml
        import base64
        import json
        import urllib.parse
        import re

        def parse_vmess(link):
            """è§£æ vmess:// é“¾æ¥"""
            try:
                b64_data = link[8:]
                b64_data += '=' * (4 - len(b64_data) % 4)
                json_str = base64.b64decode(b64_data).decode('utf-8')
                data = json.loads(json_str)
                
                node = {
                    'name': data.get('ps', 'VMess Node'),
                    'type': 'vmess',
                    'server': data.get('add', ''),
                    'port': int(data.get('port', 443)),
                    'uuid': data.get('id', ''),
                    'alterId': int(data.get('aid', 0)),
                    'cipher': 'auto',
                    'tls': data.get('tls', '') == 'tls',
                    'network': data.get('net', 'tcp'),
                    'ws-opts': {}
                }
                
                if node['network'] == 'ws':
                    node['ws-opts']['path'] = data.get('path', '/')
                    if data.get('host'):
                        node['ws-opts']['headers'] = {'Host': data['host']}
                
                if not node['server'] or not node['uuid']:
                    return None
                return node
            except Exception as e:
                return None

        def parse_vless(link):
            """è§£æ vless:// é“¾æ¥"""
            try:
                match = re.match(r'vless://([^@]+)@([^:]+):(\d+)\?([^#]+)#(.+)', link)
                if not match:
                    match = re.match(r'vless://([^@]+)@([^:]+):(\d+)\?(.+)', link)
                    if match:
                        uuid, server, port, params = match.groups()
                        name = f"VLESS-{server}"
                    else:
                        return None
                else:
                    uuid, server, port, params, name = match.groups()
                
                query = urllib.parse.parse_qs(params)
                
                node = {
                    'name': urllib.parse.unquote(name),
                    'type': 'vless',
                    'server': server,
                    'port': int(port),
                    'uuid': uuid,
                    'tls': query.get('security', [''])[0] == 'tls' or 'xtls' in query.get('security', ['']),
                    'network': query.get('type', ['tcp'])[0],
                    'udp': True
                }
                
                flow = query.get('flow', [''])[0]
                if flow:
                    node['flow'] = flow
                
                if node['network'] == 'ws':
                    node['ws-opts'] = {
                        'path': query.get('path', ['/'])[0],
                        'headers': {'Host': query.get('sni', [server])[0]}
                    }
                
                return node
            except Exception as e:
                return None

        def parse_trojan(link):
            """è§£æ trojan:// é“¾æ¥"""
            try:
                match = re.match(r'trojan://([^@]+)@([^:]+):(\d+)\?([^#]+)#(.+)', link)
                if not match:
                    match = re.match(r'trojan://([^@]+)@([^:]+):(\d+)#(.+)', link)
                    if match:
                        password, server, port, name = match.groups()
                        params = ''
                    else:
                        return None
                else:
                    password, server, port, params, name = match.groups()
                
                query = urllib.parse.parse_qs(params) if params else {}
                
                node = {
                    'name': urllib.parse.unquote(name),
                    'type': 'trojan',
                    'server': server,
                    'port': int(port),
                    'password': password,
                    'tls': True,
                    'sni': query.get('sni', [server])[0],
                    'udp': True
                }
                
                if not node['server'] or not node['password']:
                    return None
                return node
            except Exception as e:
                return None

        def parse_ss(link):
            """è§£æ ss:// é“¾æ¥"""
            try:
                content = link[5:]
                
                if '@' not in content and len(content) > 20:
                    # Base64 ç¼–ç æ ¼å¼
                    try:
                        padding = 4 - len(content) % 4
                        if padding != 4:
                            content += '=' * padding
                        decoded = base64.b64decode(content).decode('utf-8')
                        if '@' in decoded:
                            method_pass, server_port = decoded.split('@', 1)
                        else:
                            return None
                    except:
                        return None
                else:
                    match = re.match(r'(.+?)@(.+)', content)
                    if not match:
                        return None
                    method_pass = urllib.parse.unquote(match.group(1))
                    server_port = match.group(2)
                
                method, password = method_pass.split(':', 1)
                
                if '#' in server_port:
                    server_port_part, name = server_port.split('#', 1)
                    name = urllib.parse.unquote(name)
                else:
                    server_port_part = server_port
                    name = f"SS-{server_port.split(':')[0]}"
                
                server, port = server_port_part.split(':')
                
                node = {
                    'name': name,
                    'type': 'ss',
                    'server': server,
                    'port': int(port),
                    'cipher': method,
                    'password': password,
                    'udp': True
                }
                return node
            except Exception as e:
                return None

        # è¯»å–æ˜æ–‡èŠ‚ç‚¹
        with open('nodes_plain.txt', 'r', encoding='utf-8') as f:
            lines = f.readlines()

        proxies = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            node = None
            if line.startswith('vmess://'):
                node = parse_vmess(line)
            elif line.startswith('vless://'):
                node = parse_vless(line)
            elif line.startswith('trojan://'):
                node = parse_trojan(line)
            elif line.startswith('ss://'):
                node = parse_ss(line)
            
            if node:
                # å»é‡æ£€æŸ¥
                existing = [p for p in proxies if p['name'] == node['name']]
                if existing:
                    node['name'] = node['name'] + '-2'
                proxies.append(node)

        print(f"âœ“ Parsed {len(proxies)} valid nodes")

        # ç”Ÿæˆ Clash é…ç½®
        clash_config = {
            'mixed-port': 7890,
            'allow-lan': True,
            'mode': 'rule',
            'log-level': 'info',
            'external-controller': '0.0.0.0:9090',
            'dns': {
                'enable': True,
                'nameserver': ['114.114.114.114', '8.8.8.8']
            },
            'proxies': proxies,
            'proxy-groups': [
                {
                    'name': 'Auto',
                    'type': 'select',
                    'proxies': [p['name'] for p in proxies] if len(proxies) <= 50 else [p['name'] for p in proxies[:50]]
                },
                {
                    'name': 'LoadBalance',
                    'type': 'load-balance',
                    'strategy': 'consistent-hashing',
                    'proxies': [p['name'] for p in proxies],
                    'url': 'http://www.gstatic.com/generate_204',
                    'interval': 300
                }
            ],
            'rules': [
                'DOMAIN-SUFFIX,google.com,Auto',
                'DOMAIN-SUFFIX,youtube.com,Auto',
                'DOMAIN-KEYWORD,google,Auto',
                'MATCH,DIRECT'
            ]
        }

        # ç”Ÿæˆ nodes_clash.yaml
        with open('nodes_clash.yaml', 'w', encoding='utf-8') as f:
            yaml.dump(clash_config, f, default_flow_style=False, allow_unicode=True)
        print("âœ“ Generated nodes_clash.yaml")

        # ç”Ÿæˆ config.yaml (ä¾› Clash Verge ä½¿ç”¨)
        with open('config.yaml', 'w', encoding='utf-8') as f:
            yaml.dump(clash_config, f, default_flow_style=False, allow_unicode=True)
        print("âœ“ Generated config.yaml")
        EOF
        
        python3 generate_clash.py

    - name: Generate Sing-box config
      run: |
        cat > generate_singbox.py << 'EOF'
        import json

        with open('nodes_plain.txt', 'r', encoding='utf-8') as f:
            lines = [l.strip() for l in f if l.strip()]

        outbounds = [{"type": "direct", "tag": "direct"}]
        
        for i, line in enumerate(lines):
            if line.startswith(('vmess://', 'vless://', 'trojan://', 'ss://')):
                outbounds.append({
                    "type": "selector",
                    "tag": f"node_{i}",
                    "outbounds": ["direct"]
                })

        config = {
            "log": {"level": "info"},
            "dns": {"servers": [{"address": "8.8.8.8"}]},
            "outbounds": outbounds
        }

        with open('nodes_singbox.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2)
        
        print("âœ“ Generated nodes_singbox.json")
        EOF
        
        python3 generate_singbox.py

    - name: Commit and push (ä¿ç•™æ—§æ–‡ä»¶)
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        # æ·»åŠ æ–°æ–‡ä»¶ v2fgrjk å’Œç”Ÿæˆçš„é…ç½®æ–‡ä»¶
        # æ³¨æ„ï¼šä¸æ‰§è¡Œ git rmï¼Œä¿ç•™æ—§çš„ "é”‹å“¥è½¯ä»¶åº“èŠ‚ç‚¹" æ–‡ä»¶
        git add v2fgrjk nodes_plain.txt nodes_clash.yaml config.yaml nodes_singbox.json
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
        if git diff --cached --quiet; then
          echo "No changes to commit"
        else
          git commit -m "ğŸ”„ Sync: Updated from v2fgrjk [$(date '+%Y-%m-%d %H:%M')]
          
          - New source: v2fgrjk
          - Generated Clash/Sing-box configs
          - Kept old files (é”‹å“¥è½¯ä»¶åº“èŠ‚ç‚¹)"
          git push
          echo "âœ… Successfully synced v2fgrjk"
        fi
